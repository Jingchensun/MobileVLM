# from huggingface_hub import hf_hub_download

# # ä¸‹è½½ ShareGPT4V æ•°æ®é›†ä¸­çš„ LFS æ–‡ä»¶
# file_path = hf_hub_download(
#     repo_id="Lin-Chen/ShareGPT4V",
#     filename="share-captioner_coco_lcs_sam_1246k_1107.json",
#     repo_type="dataset",
#     local_dir="downloads",  # å¯é€‰ï¼šæœ¬åœ°ä¿å­˜ç›®å½•
#     local_dir_use_symlinks=False
# )

# print(f"âœ… File downloaded to: {file_path}")

# from huggingface_hub import hf_hub_download

# file_path = hf_hub_download(
#     repo_id="liuhaotian/LLaVA-Pretrain",
#     filename="images.zip",                 # æ–‡ä»¶åå¿…é¡»ç²¾ç¡®åŒ¹é…
#     repo_type="dataset",                  # æŒ‡å®šä¸º dataset ç±»å‹
#     local_dir="./my_llava_data",          # ä½ å¸Œæœ›ä¿å­˜çš„ç›®å½•
#     local_dir_use_symlinks=False          # é¿å…ä½¿ç”¨ç¬¦å·é“¾æ¥ï¼Œç›´æ¥ä¸‹è½½æ–‡ä»¶
# )

# print(f"âœ… File downloaded to: {file_path}")


import json

# æŒ‡å®šæ–‡ä»¶è·¯å¾„ï¼ˆä¿®æ”¹ä¸ºä½ çš„å®é™…è·¯å¾„ï¼‰
file_path = "share-captioner_coco_lcs_sam_1246k_1107.json"

# file_path = "filtered_sam_samples.json"

# è¯»å– JSON æ–‡ä»¶å†…å®¹ï¼ˆå‡è®¾æ˜¯ä¸€ä¸ª JSON list æ ¼å¼ï¼‰
with open(file_path, "r", encoding="utf-8") as f:
    data = json.load(f)

# ç»Ÿè®¡æ€»æ ·æœ¬æ•°é‡
total_samples = len(data)
print(f"âœ… Total samples: {total_samples}\n")

# æ‰“å°å‰ä¸‰ä¸ªæ ·æœ¬
print("ğŸ”¹ First 3 samples:")
for sample in data[:3]:
    print(json.dumps(sample, indent=2, ensure_ascii=False))

# æ‰“å°æœ€åä¸‰ä¸ªæ ·æœ¬
print("\nğŸ”¹ Last 3 samples:")
for sample in data[-3:]:
    print(json.dumps(sample, indent=2, ensure_ascii=False))
